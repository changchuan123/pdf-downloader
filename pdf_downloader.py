import os
import requests
from urllib.parse import urlparse, unquote
import time
from pathlib import Path
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import pandas as pd
import sys
from datetime import datetime

class PDFDownloader:
    def __init__(self, download_folder="downloads", max_workers=5):
        """
        åˆå§‹åŒ–PDFä¸‹è½½å™¨
        
        Args:
            download_folder (str): ä¸‹è½½æ–‡ä»¶ä¿å­˜çš„æ–‡ä»¶å¤¹è·¯å¾„
            max_workers (int): æœ€å¤§å¹¶å‘ä¸‹è½½æ•°
        """
        self.download_folder = Path(download_folder)
        self.max_workers = max_workers
        self.session = requests.Session()
        
        # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # åˆ›å»ºä¸‹è½½æ–‡ä»¶å¤¹
        self.download_folder.mkdir(parents=True, exist_ok=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.success_count = 0
        self.failed_count = 0
        self.failed_urls = []
        
        # æ–‡ä»¶åè®¡æ•°å™¨ï¼Œç”¨äºå¤„ç†é‡å¤æ–‡ä»¶å
        self.filename_counter = {}
        
    def get_filename_from_url(self, url):
        """ä»URLä¸­æå–æ–‡ä»¶å"""
        parsed_url = urlparse(url)
        filename = os.path.basename(unquote(parsed_url.path))
        
        # å¦‚æœURLä¸­æ²¡æœ‰æ–‡ä»¶åï¼Œç”Ÿæˆä¸€ä¸ªåŸºäºURLçš„æ–‡ä»¶å
        if not filename or filename == '/' or '.' not in filename:
            # ä½¿ç”¨åŸŸååŠ ä¸Šè·¯å¾„çš„hashä½œä¸ºæ–‡ä»¶å
            domain = parsed_url.netloc.replace('www.', '').replace('.', '_')
            url_hash = abs(hash(url)) % 10000
            filename = f"{domain}_{url_hash}.pdf"
        
        # ç¡®ä¿æœ‰æ‰©å±•å
        if not filename.lower().endswith(('.pdf', '.doc', '.docx', '.txt', '.jpg', '.png', '.gif')):
            filename += '.pdf'
            
        return filename
    
    def get_unique_filename(self, base_filename):
        """è·å–å”¯ä¸€çš„æ–‡ä»¶åï¼Œå¤„ç†é‡å¤æƒ…å†µ"""
        file_path = self.download_folder / base_filename
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›
        if not file_path.exists():
            return base_filename
        
        # å¤„ç†é‡å¤æ–‡ä»¶åï¼Œæ·»åŠ -1ã€-2ã€-3ç­‰åç¼€
        name_stem = file_path.stem
        name_suffix = file_path.suffix
        counter = 1
        
        while True:
            new_filename = f"{name_stem}-{counter}{name_suffix}"
            new_file_path = self.download_folder / new_filename
            if not new_file_path.exists():
                return new_filename
            counter += 1
    
    def download_single_pdf(self, url):
        """
        ä¸‹è½½å•ä¸ªPDFæ–‡ä»¶ï¼Œä½¿ç”¨URLè‡ªåŠ¨æå–çš„æ–‡ä»¶å
        
        Args:
            url (str): PDFæ–‡ä»¶çš„ä¸‹è½½é“¾æ¥
        
        Returns:
            tuple: (æˆåŠŸæ ‡å¿—, æ–‡ä»¶è·¯å¾„æˆ–é”™è¯¯ä¿¡æ¯)
        """
        try:
            # ä»URLæå–æ–‡ä»¶å
            filename = self.get_filename_from_url(url)
            
            # è·å–å”¯ä¸€æ–‡ä»¶åï¼ˆå¤„ç†é‡å¤ï¼‰
            unique_filename = self.get_unique_filename(filename)
            file_path = self.download_folder / unique_filename
            
            print(f"æ­£åœ¨ä¸‹è½½: {url}")
            print(f"ä¿å­˜ä¸º: {unique_filename}")
            
            # å‘é€è¯·æ±‚ä¸‹è½½æ–‡ä»¶
            response = self.session.get(url, stream=True, timeout=30)
            response.raise_for_status()
            
            # æ£€æŸ¥Content-Typeå¹¶ç¡®å®šæ–‡ä»¶æ‰©å±•å
            content_type = response.headers.get('content-type', '').lower()
            
            # æ ¹æ®Content-Typeè°ƒæ•´æ‰©å±•å
            if 'application/pdf' in content_type or 'pdf' in content_type:
                if not unique_filename.lower().endswith('.pdf'):
                    unique_filename = f"{Path(unique_filename).stem}.pdf"
                    file_path = self.download_folder / unique_filename
            elif 'image/jpeg' in content_type or 'image/jpg' in content_type:
                if not unique_filename.lower().endswith(('.jpg', '.jpeg')):
                    unique_filename = f"{Path(unique_filename).stem}.jpg"
                    file_path = self.download_folder / unique_filename
            elif 'image/png' in content_type:
                if not unique_filename.lower().endswith('.png'):
                    unique_filename = f"{Path(unique_filename).stem}.png"
                    file_path = self.download_folder / unique_filename
            
            # ä¿å­˜æ–‡ä»¶
            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            
            file_size = file_path.stat().st_size
            print(f"ä¸‹è½½å®Œæˆ: {unique_filename} ({file_size} bytes)")
            
            return True, str(file_path)
            
        except requests.exceptions.RequestException as e:
            error_msg = f"ä¸‹è½½å¤±è´¥ {url}: ç½‘ç»œé”™è¯¯ - {str(e)}"
            print(error_msg)
            return False, error_msg
            
        except Exception as e:
            error_msg = f"ä¸‹è½½å¤±è´¥ {url}: {str(e)}"
            print(error_msg)
            return False, error_msg
    
    def download_from_list(self, url_list):
        """
        ä»URLåˆ—è¡¨æ‰¹é‡ä¸‹è½½PDFï¼Œä½¿ç”¨URLè‡ªåŠ¨æå–æ–‡ä»¶å
        
        Args:
            url_list (list): PDFä¸‹è½½é“¾æ¥åˆ—è¡¨
        """
        print(f"å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(url_list)} ä¸ªæ–‡ä»¶...")
        print(f"ä¿å­˜ç›®å½•: {self.download_folder.absolute()}")
        print(f"æ–‡ä»¶å‘½å: ä½¿ç”¨URLè‡ªåŠ¨æå–æ–‡ä»¶å")
        print(f"å¹¶å‘æ•°: {self.max_workers}")
        print("-" * 50)
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ä¸‹è½½
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_url = {
                executor.submit(self.download_single_pdf, url): url
                for url in url_list
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    success, result = future.result()
                    if success:
                        self.success_count += 1
                    else:
                        self.failed_count += 1
                        self.failed_urls.append(url)
                except Exception as e:
                    self.failed_count += 1
                    self.failed_urls.append(url)
                    print(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸ {url}: {str(e)}")
        
        self.print_summary()
    
    def download_from_file(self, urls_file_path, encoding='utf-8'):
        """
        ä»æ–‡ä»¶ä¸­è¯»å–URLåˆ—è¡¨å¹¶ä¸‹è½½
        
        Args:
            urls_file_path (str): åŒ…å«URLåˆ—è¡¨çš„æ–‡ä»¶è·¯å¾„
            encoding (str): æ–‡ä»¶ç¼–ç 
        """
        try:
            with open(urls_file_path, 'r', encoding=encoding) as f:
                urls = [line.strip() for line in f if line.strip()]
            
            print(f"ä»æ–‡ä»¶ {urls_file_path} è¯»å–åˆ° {len(urls)} ä¸ªURL")
            self.download_from_list(urls)
            
        except Exception as e:
            print(f"è¯»å–URLæ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def download_from_excel(self, excel_path):
        """
        ä»Excelæ–‡ä»¶è¯»å–æ–‡ä»¶åå’ŒURLåˆ—è¡¨å¹¶ä¸‹è½½
        ç¬¬ä¸€åˆ—ï¼šæ–‡ä»¶åï¼Œç¬¬äºŒåˆ—ï¼šURL
        
        Args:
            excel_path (str): Excelæ–‡ä»¶è·¯å¾„
        """
        try:
            # è¯»å–Excelæ–‡ä»¶ï¼Œä¸å°†ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´ï¼ŒæŒ‡å®šå¼•æ“
            df = pd.read_excel(excel_path, header=None, engine='openpyxl')
            
            # æ£€æŸ¥æ•°æ®æ˜¯å¦æœ‰æ•ˆ
            if len(df) == 0:
                print("âŒ é”™è¯¯: Excelæ–‡ä»¶ä¸ºç©º")
                return
            
            # ç¬¬ä¸€åˆ—ä¸ºæ–‡ä»¶åï¼Œç¬¬äºŒåˆ—ä¸ºURL
            urls = []
            filenames = []
            
            # å¤„ç†æ¯ä¸€è¡Œæ•°æ®
            for index, row in df.iterrows():
                filename_cell = row[0] if 0 in row else None
                url_cell = row[1] if 1 in row else None
                
                # æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆ
                if pd.isna(url_cell) or not str(url_cell).strip():
                    print(f"âš ï¸  è·³è¿‡ç¬¬{index+1}è¡Œï¼šURLä¸ºç©º")
                    continue
                
                # å¤„ç†æ–‡ä»¶å
                if pd.isna(filename_cell) or not str(filename_cell).strip():
                    # å¦‚æœæ–‡ä»¶åä¸ºç©ºï¼Œä»URLè‡ªåŠ¨æå–
                    filename = self.get_filename_from_url(str(url_cell).strip())
                    print(f"ğŸ“ ç¬¬{index+1}è¡Œæ–‡ä»¶åä¸ºç©ºï¼Œè‡ªåŠ¨æå–ä¸º: {filename}")
                else:
                    filename = str(filename_cell).strip()
                    # ç¡®ä¿æœ‰æ‰©å±•å
                    if not filename.lower().endswith(('.pdf', '.doc', '.docx', '.txt', '.jpg', '.png', '.gif')):
                        filename += '.pdf'
                
                urls.append(str(url_cell).strip())
                filenames.append(filename)
            
            print(f"ä»Excelæ–‡ä»¶ {excel_path} è¯»å–åˆ° {len(urls)} ä¸ªä¸‹è½½ä»»åŠ¡")
            print("ğŸ“ æ–‡ä»¶å‘½å: ä½¿ç”¨Excelç¬¬ä¸€åˆ—æŒ‡å®šçš„æ–‡ä»¶å")
            print("ğŸ“ é‡å¤æ–‡ä»¶: è‡ªåŠ¨æ·»åŠ -1ã€-2ã€-3ç­‰åç¼€")
            
            # å¼€å§‹ä¸‹è½½
            self.download_from_list_with_names(urls, filenames)
            
        except Exception as e:
            print(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥: {str(e)}")
            print("è¯·ç¡®ä¿Excelæ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼šç¬¬ä¸€åˆ—ä¸ºæ–‡ä»¶åï¼Œç¬¬äºŒåˆ—ä¸ºURL")
    
    def download_from_list_with_names(self, url_list, filename_list):
        """
        ä»URLåˆ—è¡¨å’Œæ–‡ä»¶ååˆ—è¡¨æ‰¹é‡ä¸‹è½½
        
        Args:
            url_list (list): PDFä¸‹è½½é“¾æ¥åˆ—è¡¨
            filename_list (list): å¯¹åº”çš„æ–‡ä»¶ååˆ—è¡¨
        """
        print(f"å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(url_list)} ä¸ªæ–‡ä»¶...")
        print(f"ä¿å­˜ç›®å½•: {self.download_folder.absolute()}")
        print(f"æ–‡ä»¶å‘½å: ä½¿ç”¨æŒ‡å®šçš„æ–‡ä»¶å")
        print(f"å¹¶å‘æ•°: {self.max_workers}")
        print("-" * 50)
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ä¸‹è½½
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {
                executor.submit(self.download_single_pdf_with_name, url, filename): (url, filename)
                for url, filename in zip(url_list, filename_list)
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_task):
                url, filename = future_to_task[future]
                try:
                    success, result = future.result()
                    if success:
                        self.success_count += 1
                    else:
                        self.failed_count += 1
                        self.failed_urls.append(url)
                except Exception as e:
                    self.failed_count += 1
                    self.failed_urls.append(url)
                    print(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸ {url}: {str(e)}")
        
        self.print_summary()
    
    def download_single_pdf_with_name(self, url, filename):
        """
        ä¸‹è½½å•ä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨æŒ‡å®šçš„æ–‡ä»¶å
        
        Args:
            url (str): æ–‡ä»¶ä¸‹è½½é“¾æ¥
            filename (str): æŒ‡å®šçš„æ–‡ä»¶å
        
        Returns:
            tuple: (æˆåŠŸæ ‡å¿—, æ–‡ä»¶è·¯å¾„æˆ–é”™è¯¯ä¿¡æ¯)
        """
        try:
            # è·å–å”¯ä¸€æ–‡ä»¶åï¼ˆå¤„ç†é‡å¤ï¼‰
            unique_filename = self.get_unique_filename(filename)
            file_path = self.download_folder / unique_filename
            
            print(f"æ­£åœ¨ä¸‹è½½: {url}")
            print(f"ä¿å­˜ä¸º: {unique_filename}")
            
            # å‘é€è¯·æ±‚ä¸‹è½½æ–‡ä»¶
            response = self.session.get(url, stream=True, timeout=30)
            response.raise_for_status()
            
            # ä¿å­˜æ–‡ä»¶
            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            
            file_size = file_path.stat().st_size
            print(f"ä¸‹è½½å®Œæˆ: {unique_filename} ({file_size} bytes)")
            
            return True, str(file_path)
            
        except requests.exceptions.RequestException as e:
            error_msg = f"ä¸‹è½½å¤±è´¥ {url}: ç½‘ç»œé”™è¯¯ - {str(e)}"
            print(error_msg)
            return False, error_msg
            
        except Exception as e:
            error_msg = f"ä¸‹è½½å¤±è´¥ {url}: {str(e)}"
            print(error_msg)
            return False, error_msg

    def print_summary(self):
        """æ‰“å°ä¸‹è½½ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 50)
        print("ä¸‹è½½å®Œæˆç»Ÿè®¡:")
        print(f"æˆåŠŸ: {self.success_count}")
        print(f"å¤±è´¥: {self.failed_count}")
        print(f"æ€»è®¡: {self.success_count + self.failed_count}")
        
        if self.failed_urls:
            print("\nå¤±è´¥çš„URL:")
            for url in self.failed_urls:
                print(f"  - {url}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ä¿®å¤æ–‡ä»¶è·¯å¾„é—®é¢˜ï¼šè·å–exeæ‰€åœ¨ç›®å½•æˆ–å½“å‰å·¥ä½œç›®å½•
    if getattr(sys, 'frozen', False):
        # å¦‚æœæ˜¯æ‰“åŒ…åçš„exeæ–‡ä»¶
        project_path = os.path.dirname(sys.executable)
    else:
        # å¦‚æœæ˜¯Pythonè„šæœ¬
        project_path = os.path.dirname(os.path.abspath(__file__))
    
    # å¦‚æœä¸Šè¿°è·¯å¾„åœ¨ä¸´æ—¶ç›®å½•ä¸­ï¼Œä½¿ç”¨å½“å‰å·¥ä½œç›®å½•
    if "Temp" in project_path or "temp" in project_path or "_MEI" in project_path:
        project_path = os.getcwd()
    
    # ä¼˜å…ˆä½¿ç”¨æµ‹è¯•æ–‡ä»¶
    test_file = os.path.join(project_path, "test_urls.xlsx")
    if os.path.exists(test_file):
        urls_file = test_file
    else:
        urls_file = os.path.join(project_path, "urls.xlsx")
    
    # åˆ›å»ºæŒ‰æ—¶é—´æˆ³å‘½åçš„ä¸‹è½½æ–‡ä»¶å¤¹
    current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
    download_folder = os.path.join(project_path, f"ä¸‹è½½_{current_time}")
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(urls_file):
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°Excelæ–‡ä»¶")
        print(f"è¯·åœ¨ç¨‹åºç›®å½•åˆ›å»ºä»¥ä¸‹æ–‡ä»¶ä¹‹ä¸€:")
        print(f"  - test_urls.xlsx (æµ‹è¯•æ–‡ä»¶)")
        print(f"  - urls.xlsx (æ­£å¼æ–‡ä»¶)")
        print(f"å½“å‰ç›®å½•: {project_path}")
        print("\nExcelæ–‡ä»¶æ ¼å¼è¦æ±‚:")
        print("  ç¬¬ä¸€åˆ—: æ–‡ä»¶å")
        print("  ç¬¬äºŒåˆ—: ä¸‹è½½é“¾æ¥URL")
        input("æŒ‰å›è½¦é”®é€€å‡º...")
        exit(1)
    
    print("PDFæ‰¹é‡ä¸‹è½½å·¥å…·")
    print("=" * 50)
    print(f"ç¨‹åºç›®å½•: {project_path}")
    print(f"Excelæ–‡ä»¶: {urls_file}")
    print(f"ä¸‹è½½ç›®å½•: {download_folder}")
    print(f"ä¸‹è½½æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("-" * 50)
    
    # åˆ›å»ºä¸‹è½½å™¨å®ä¾‹
    downloader = PDFDownloader(
        download_folder=download_folder,
        max_workers=3  # å¹¶å‘ä¸‹è½½æ•°
    )
    
    # ç›´æ¥ä½¿ç”¨Excelæ–‡ä»¶ä¸‹è½½
    if urls_file.lower().endswith(('.xlsx', '.xls')):
        downloader.download_from_excel(urls_file)
    else:
        downloader.download_from_file(urls_file)
    
    print("\nâœ… ä¸‹è½½ä»»åŠ¡å®Œæˆï¼")
    print(f"æ–‡ä»¶ä¿å­˜åœ¨: {download_folder}")
    input("æŒ‰å›è½¦é”®é€€å‡º...")
